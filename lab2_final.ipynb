{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakeC05/Engineering-Methods/blob/main/lab2_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rk6CdideCrmL"
      },
      "outputs": [],
      "source": [
        "from sympy import Matrix, symbols\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 1: Finding Eigenvalues and Eigenvectors for Diagonalization**\n",
        "\n",
        "The goal of this problem is to compute the eigenvalues/eigenvectors of a matrix, then diagonalize when possible."
      ],
      "metadata": {
        "id": "FWhoDbkiMKiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the matrix\n",
        "M = Matrix([[2, 1, 0, 0],\n",
        "    [1, 2, 0, 0],\n",
        "    [0, 0, 3, 1],\n",
        "    [0, 0, 1, 3]])\n",
        "\n",
        "# Display\n",
        "M"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "r6BdQsUfJuYl",
        "outputId": "145ec916-74a4-4dc8-a5a7-166b8d152739"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[2, 1, 0, 0],\n",
              "[1, 2, 0, 0],\n",
              "[0, 0, 3, 1],\n",
              "[0, 0, 1, 3]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}2 & 1 & 0 & 0\\\\1 & 2 & 0 & 0\\\\0 & 0 & 3 & 1\\\\0 & 0 & 1 & 3\\end{matrix}\\right]$"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(a) Characteristic Polynomial**\n",
        "To find the characteristic polynomial of $M$, we need to instantiate an algebraic variable: we do this by using `symbols()`. For example, if we want x to represent an algebraic variable, then we write `x = symbols('x')` (notice the quotations on the inside, this data-structure is known as a **string**). Then the characteristic polynomial can be written as `char_poly = (M-x*I).det()`, where the identity matrix $I$ is given by `Matrix.eye(4)`\n",
        "\n",
        "**Create the characteristic polynomial under `char_poly` of the matrix $M$.**\n"
      ],
      "metadata": {
        "id": "cBMLRIzcrrWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variable\n",
        "x=symbols('x')\n",
        "# Characteristic polynomial\n",
        "I = Matrix.eye(4) # 4 since A is a 4x4 matrix\n",
        "char_poly=(M-x*I).det()\n",
        "#display\n",
        "char_poly"
      ],
      "metadata": {
        "id": "1PBmbOzROSMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "40ffd820-f509-45a9-f1dc-b625cb74dab8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(x**2 - 6*x + 8)*(x**2 - 4*x + 3)"
            ],
            "text/latex": "$\\displaystyle \\left(x^{2} - 6 x + 8\\right) \\left(x^{2} - 4 x + 3\\right)$"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(b) Eigenvalues**\n",
        "For a matrix $M$, then `M.eigvals()` returns a set of the form $\\{\\text{eigenvalues of A}:\\text{algebraic multiplicity}\\}$, where the **algebraic multiplicity** of an eigenvalue $\\lambda$ is the maximum integer $k$ such that $(x-\\lambda)^k$ divides the characteristic polynomial $\\det(M-xI)$.\n",
        "\n",
        "**Compute the eigenenvalues of $M$. From this, deduce whether $M$ is diagonalizable.**"
      ],
      "metadata": {
        "id": "ePxGKQtvoE9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute eigenvalues here\n",
        "M.eigenvals()\n"
      ],
      "metadata": {
        "id": "9yX2tKFVJwAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a7af17-72f6-42d9-8dc5-ed9c2fc93dce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 1, 1: 1, 4: 1, 2: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: 1,2,3,4 all multiplicity of 1"
      ],
      "metadata": {
        "id": "PwXEj2X4q7oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(c) Eigenvectors**\n",
        "\n",
        "SymPy can find eigenvectors with `M.eigenvects()`.\n",
        "\n",
        "1. Use `M.eigenvects()` to see the eigenvalues, their algebraic multiplicities,\n",
        "   and bases for each eigenspace $E_\\lambda$.\n",
        "2. For each eigenvalue, pick one eigenvector and write it down.\n",
        "3. For one eigenpair $(\\lambda, v)$, verify by hand (or in code) that\n",
        "   $$\n",
        "   M v = \\lambda v.\n",
        "   $$\n"
      ],
      "metadata": {
        "id": "_IBwyy5Eqok2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.\n",
        "M.eigenvects()"
      ],
      "metadata": {
        "id": "Hp0VrEBf0ZBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f3a981-9bb1-4e4b-af2f-10bcc8f70ebb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1,\n",
              "  1,\n",
              "  [Matrix([\n",
              "   [-1],\n",
              "   [ 1],\n",
              "   [ 0],\n",
              "   [ 0]])]),\n",
              " (2,\n",
              "  1,\n",
              "  [Matrix([\n",
              "   [ 0],\n",
              "   [ 0],\n",
              "   [-1],\n",
              "   [ 1]])]),\n",
              " (3,\n",
              "  1,\n",
              "  [Matrix([\n",
              "   [1],\n",
              "   [1],\n",
              "   [0],\n",
              "   [0]])]),\n",
              " (4,\n",
              "  1,\n",
              "  [Matrix([\n",
              "   [0],\n",
              "   [0],\n",
              "   [1],\n",
              "   [1]])])]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2,3:\n",
        "Did $Av = \\lambda v$?\n",
        "\n",
        "Answer (Binary):"
      ],
      "metadata": {
        "id": "p592aWnHzzwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(d) Diagonalization**\n",
        "\n",
        "A matrix $M$ is **diagonalizable** if it is similar to diagonal matrix $D$: that is, if we can find an invertible matrix $P$ and a diagonal matrix $D$\n",
        "such that\n",
        "$$\n",
        "M = P D P^{-1},\n",
        "$$\n",
        "where the columns of $P$ are eigenvectors of $M$ and the diagonal entries of $D$ are the eigenvalues.\n",
        "\n",
        "1. Use `M.diagonalize()` to compute matrices $P$ and $D$.\n",
        "- This gives a tuple, so you want `P,D = M.diagonalize()`\n",
        "2. Check in code that `P.inv()*M*P` really equals $D$.\n",
        "3. Why does having 4 linearly independent eigenvectors imply that $M$ is diagonalizable?"
      ],
      "metadata": {
        "id": "pNamxFyOqanu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Compute P and D\n",
        "\n",
        "P,D=M.diagonalize()\n",
        "\n",
        "display (P)\n"
      ],
      "metadata": {
        "id": "1jDtDH3oKHBY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "88a28293-5e16-4be9-df50-a22615d64042"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[-1,  0, 1, 0],\n",
              "[ 1,  0, 1, 0],\n",
              "[ 0, -1, 0, 1],\n",
              "[ 0,  1, 0, 1]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}-1 & 0 & 1 & 0\\\\1 & 0 & 1 & 0\\\\0 & -1 & 0 & 1\\\\0 & 1 & 0 & 1\\end{matrix}\\right]$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display (D)\n"
      ],
      "metadata": {
        "id": "U_7dldkHK7wh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "dfca70d2-e4a4-4cb5-81d5-b6fb60e69aec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[1, 0, 0, 0],\n",
              "[0, 2, 0, 0],\n",
              "[0, 0, 3, 0],\n",
              "[0, 0, 0, 4]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\0 & 2 & 0 & 0\\\\0 & 0 & 3 & 0\\\\0 & 0 & 0 & 4\\end{matrix}\\right]$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Check whether P.inv()*M*P == D is true\n",
        "P.inv()*M*P==D"
      ],
      "metadata": {
        "id": "sS6Uf-wF2ZKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4249b4f6-0d81-43d9-a1bc-88358c862391"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to 3: This let's us build the matrix $P$. If we did not have enough eigenvectors, then we would not be able to build $P$: any collection of eigenvectors of $M$ would build a singular matrix $P$."
      ],
      "metadata": {
        "id": "sTuDUdPT20iR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2 â€” Audience Attention in a 11-Actor Play\n",
        "\n",
        "Eleven actors stand in a line on stage. At each \"beat\" of a performance,\n",
        "the audience's attention shifts between them according to simple rules:\n",
        "\n",
        "- Actors **1** and **11** (edges) keep 60% of their attention and send 40% to their single neighbor.\n",
        "- Actors **2-5** and **7-10** (non-center,non-edge) keep 60% of attention, sends 20% to the neighbor on the left, and 20% to the neighbor on the right.\n",
        "- Actor **6** keeps 85% of attention, sends 7.5% to Actor **10**, and 7.5% to Actor **12**.\n",
        "\n",
        "\n",
        "Let $x_k$ be the vector representing the attention vector after the $k$-th beat.\n",
        "\n",
        "The update rule is linear: $x_{k+1} = A x_k$,\n",
        "where $A$ is the matrix\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "0.6 & 0.2 & 0.0 & 0.0 & 0.0 & 0.0  & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
        "0.4 & 0.6 & 0.2 & 0.0 & 0.0 & 0.0  & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
        "0.0 & 0.2 & 0.6 & 0.2 & 0.0 & 0.0  & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
        "0.0 & 0.0 & 0.2 & 0.6 & 0.2 & 0.0  & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
        "0.0 & 0.0 & 0.0 & 0.2 & 0.6 & 0.075& 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
        "0.0 & 0.0 & 0.0 & 0.0 & 0.2 & 0.85 & 0.2 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
        "0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.075& 0.6 & 0.2 & 0.0 & 0.0 & 0.0 \\\\\n",
        "0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  & 0.2 & 0.6 & 0.2 & 0.0 & 0.0 \\\\\n",
        "0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  & 0.0 & 0.2 & 0.6 & 0.2 & 0.0 \\\\\n",
        "0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  & 0.0 & 0.0 & 0.2 & 0.6 & 0.4 \\\\\n",
        "0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  & 0.0 & 0.0 & 0.0 & 0.2 & 0.6\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "We call $A$ the ***attention-flow matrix***.\n",
        "\n",
        "Famous actor Bedro Bascall is in the center of the line-up as actor 6, so we begin with all attention focused on Actor 6:\n",
        "$$\n",
        "x_0 :=   [0,0,0,0,0,100,0,0,0,0,0]^T.\n",
        "$$\n",
        "\n",
        "Thus $x_k := A^kx_0$ measures the exact amount of attention each actor has after k beats, assuming the play begins with the audience looking entirely at Actor 6.\n",
        "\n",
        "\n",
        "We will:\n",
        "1. Simulate this system numerically using NumPy.  \n",
        "2. Diagonalize the matrix.  \n",
        "3. Interpret the long-term behavior."
      ],
      "metadata": {
        "id": "M0GQGxwXO9WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load A\n",
        "\n",
        "A =  Matrix([\n",
        "    [0.6, 0.2, 0.0, 0.0,   0.0,   0.0,   0.0,  0.0,  0.0,  0.0,  0.0],\n",
        "    [0.4, 0.6, 0.2, 0.0,   0.0,   0.0,   0.0,  0.0,  0.0,  0.0,  0.0],\n",
        "    [0.0, 0.2, 0.6, 0.2,   0.0,   0.0,   0.0,  0.0,  0.0,  0.0,  0.0],\n",
        "    [0.0, 0.0, 0.2, 0.6,   0.2,   0.0,   0.0,  0.0,  0.0,  0.0,  0.0],\n",
        "    [0.0, 0.0, 0.0, 0.2,   0.6,   0.075, 0.0,  0.0,  0.0,  0.0,  0.0],\n",
        "    [0.0, 0.0, 0.0, 0.0,   0.2,   0.85,  0.2,  0.0,  0.0,  0.0,  0.0],\n",
        "    [0.0, 0.0, 0.0, 0.0,   0.0,   0.075, 0.6,  0.2,  0.0,  0.0,  0.0],\n",
        "    [0.0, 0.0, 0.0, 0.0,   0.0,   0.0,   0.2,  0.6,  0.2,  0.0,  0.0],\n",
        "    [0.0, 0.0, 0.0, 0.0,   0.0,   0.0,   0.0,  0.2,  0.6,  0.2,  0.0],\n",
        "    [0.0, 0.0, 0.0, 0.0,   0.0,   0.0,   0.0,  0.0,  0.2,  0.6,  0.4],\n",
        "    [0.0, 0.0, 0.0, 0.0,   0.0,   0.0,   0.0,  0.0,  0.0,  0.2,  0.6],\n",
        "])\n",
        "# Load x0\n",
        "x0 = Matrix([\n",
        "    0,\n",
        "    0,\n",
        "    0,\n",
        "    0,\n",
        "    0,\n",
        "    100,  # Bedro Bascal (actor 6)\n",
        "    0,\n",
        "    0,\n",
        "    0,\n",
        "    0,\n",
        "    0\n",
        "])\n",
        "\n",
        "A"
      ],
      "metadata": {
        "id": "7jNGFvIRO3ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5e2566a7-dab2-4585-bfcd-803fbae8d324"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[0.6, 0.2, 0.0, 0.0, 0.0,   0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "[0.4, 0.6, 0.2, 0.0, 0.0,   0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "[0.0, 0.2, 0.6, 0.2, 0.0,   0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "[0.0, 0.0, 0.2, 0.6, 0.2,   0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "[0.0, 0.0, 0.0, 0.2, 0.6, 0.075, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              "[0.0, 0.0, 0.0, 0.0, 0.2,  0.85, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
              "[0.0, 0.0, 0.0, 0.0, 0.0, 0.075, 0.6, 0.2, 0.0, 0.0, 0.0],\n",
              "[0.0, 0.0, 0.0, 0.0, 0.0,   0.0, 0.2, 0.6, 0.2, 0.0, 0.0],\n",
              "[0.0, 0.0, 0.0, 0.0, 0.0,   0.0, 0.0, 0.2, 0.6, 0.2, 0.0],\n",
              "[0.0, 0.0, 0.0, 0.0, 0.0,   0.0, 0.0, 0.0, 0.2, 0.6, 0.4],\n",
              "[0.0, 0.0, 0.0, 0.0, 0.0,   0.0, 0.0, 0.0, 0.0, 0.2, 0.6]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{array}{ccccccccccc}0.6 & 0.2 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.4 & 0.6 & 0.2 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.2 & 0.6 & 0.2 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.2 & 0.6 & 0.2 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.2 & 0.6 & 0.075 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.2 & 0.85 & 0.2 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.075 & 0.6 & 0.2 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.2 & 0.6 & 0.2 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.2 & 0.6 & 0.2 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.2 & 0.6 & 0.4\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.2 & 0.6\\end{array}\\right]$"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(a) Applying the matrix several times**\n",
        "\n",
        "Compute $x_1 = A x_0$, $x_{10} = A^{10} x_0$, and $x_{1000} = A^{1000} x_0$.\n"
      ],
      "metadata": {
        "id": "Om-yy57FUvOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute x1\n",
        "x1=A*x0"
      ],
      "metadata": {
        "id": "vyjFdZt5UBu8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute x10\n",
        "x10=A**10*x0"
      ],
      "metadata": {
        "id": "-1EI3y4OZY_2",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute x1000\n",
        "x1000=A**1000*x0"
      ],
      "metadata": {
        "id": "1NUvVUuJZp7j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(b) Intrepretation**\n",
        "  Look at the entries of the vectors from (a):\n",
        "   1. How does attention spread from Actor 6 to the others?\n",
        "   2. Does the **total** attention (sum of all 11 entries of $x_k$) change? (You can compute this with `sum(x1)`)"
      ],
      "metadata": {
        "id": "eDh53lj1b2sU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 1: Attention spreads from actor 3 outward. After a few beats, attention begins spread out to the other actors. It seems like the vector converges to a vector somewhat of the form $$[4.29,8.57,\\cdots, 8.57,4.29 ]^T$$"
      ],
      "metadata": {
        "id": "4puKKHhkTT-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Compute the sum of the entries of x1, x5, and x10: compute using sum()\n",
        "print(sum(x1))\n",
        "print(sum(x10))\n",
        "print(sum(x1000))"
      ],
      "metadata": {
        "id": "dEFQmeNhTRvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48da805c-ce1a-4fa2-9d78-9f8a39ca75ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.000000000000\n",
            "100.000000000000\n",
            "100.000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 2: They all add to 100. Notice that the last entry has computational error from the computer."
      ],
      "metadata": {
        "id": "00VDadhjcIxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(c) Diagonalization and long-term behavior**\n",
        "\n",
        "Recall: SymPy can diagonalize $A$ with `A.diagonalize()`.\n",
        "\n",
        "Compute matrices $P$ and $D$ such that\n",
        "   $$\n",
        "   A = P D P^{-1}.\n",
        "   $$\n",
        "\n"
      ],
      "metadata": {
        "id": "ira5sIvXivKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagonalize A: construct P, D.\n",
        "P,D=A.diagonalize()\n",
        "\n",
        "display (D)\n"
      ],
      "metadata": {
        "id": "ZFIl-RvOix5t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "c7a357df-334c-4297-9ad8-98561caed5cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[0.217430396420866,                 0,                0,                 0,                 0,   0,                 0,                 0,   0,                 0,                 0],\n",
              "[                0, 0.219577393481939,                0,                 0,                 0,   0,                 0,                 0,   0,                 0,                 0],\n",
              "[                0,                 0, 0.34728727110711,                 0,                 0,   0,                 0,                 0,   0,                 0,                 0],\n",
              "[                0,                 0,                0, 0.364885899083011,                 0,   0,                 0,                 0,   0,                 0,                 0],\n",
              "[                0,                 0,                0,                 0, 0.560264290747211,   0,                 0,                 0,   0,                 0,                 0],\n",
              "[                0,                 0,                0,                 0,                 0, 0.6,                 0,                 0,   0,                 0,                 0],\n",
              "[                0,                 0,                0,                 0,                 0,   0, 0.782272257422226,                 0,   0,                 0,                 0],\n",
              "[                0,                 0,                0,                 0,                 0,   0,                 0, 0.835114100916989,   0,                 0,                 0],\n",
              "[                0,                 0,                0,                 0,                 0,   0,                 0,                 0, 1.0,                 0,                 0],\n",
              "[                0,                 0,                0,                 0,                 0,   0,                 0,                 0,   0, 0.980422606518061,                 0],\n",
              "[                0,                 0,                0,                 0,                 0,   0,                 0,                 0,   0,                 0, 0.942745784302588]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{array}{ccccccccccc}0.217430396420866 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0.219577393481939 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0.34728727110711 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0.364885899083011 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0.560264290747211 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0.6 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0.782272257422226 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.835114100916989 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1.0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.980422606518061 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.942745784302588\\end{array}\\right]$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (c) Approximating $\\lim_{k\\rightarrow \\infty}A^kx_0$\n",
        "We want to approximate the above limit by setting $k$ to be a gigantic number, but this is computationally expensive. Thus we will use $A=PDP^{-1}$ and take high powers of the left-hand side.\n",
        "\n",
        "1. Compute $PD^{\\text{big_num}}P^{-1}$, where big_num $= 10^{50}$.\n",
        "2. Approximate $\\lim_{k\\rightarrow \\infty}x_{k}$."
      ],
      "metadata": {
        "id": "Lm84CjmqaBWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "# construct big_n\n",
        "\n",
        "# Compute PD^(big_n)P^{-1}\n",
        "big_num=10**50\n",
        "\n",
        "P*D**(big_num)*P.inv()\n"
      ],
      "metadata": {
        "id": "Rj3lyL0UXPzO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "96f4ba67-8ee3-43d7-e4a7-fb12d6b09a4e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[0.0428571428571429, 0.0428571428571429, 0.0428571428571429, 0.0428571428571429, 0.0428571428571429, 0.0428571428571428, 0.0428571428571428, 0.0428571428571429, 0.0428571428571429, 0.0428571428571429, 0.0428571428571429],\n",
              "[0.0857142857142858, 0.0857142857142858, 0.0857142857142858, 0.0857142857142858, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142858, 0.0857142857142858, 0.0857142857142858],\n",
              "[0.0857142857142858, 0.0857142857142858, 0.0857142857142858, 0.0857142857142858, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142858, 0.0857142857142858, 0.0857142857142858],\n",
              "[0.0857142857142857, 0.0857142857142858, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142858, 0.0857142857142858],\n",
              "[0.0857142857142857, 0.0857142857142858, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142858, 0.0857142857142858],\n",
              "[ 0.228571428571429,  0.228571428571429,  0.228571428571429,  0.228571428571429,  0.228571428571429,  0.228571428571428,  0.228571428571428,  0.228571428571429,  0.228571428571429,  0.228571428571429,  0.228571428571429],\n",
              "[0.0857142857142857, 0.0857142857142858, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142858, 0.0857142857142858],\n",
              "[0.0857142857142857, 0.0857142857142858, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142858, 0.0857142857142858],\n",
              "[0.0857142857142858, 0.0857142857142858, 0.0857142857142858, 0.0857142857142858, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142858, 0.0857142857142858, 0.0857142857142858],\n",
              "[0.0857142857142858, 0.0857142857142858, 0.0857142857142858, 0.0857142857142858, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142857, 0.0857142857142858, 0.0857142857142858, 0.0857142857142858],\n",
              "[0.0428571428571429, 0.0428571428571429, 0.0428571428571429, 0.0428571428571429, 0.0428571428571429, 0.0428571428571428, 0.0428571428571428, 0.0428571428571429, 0.0428571428571429, 0.0428571428571429, 0.0428571428571429]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{array}{ccccccccccc}0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571428 & 0.0428571428571428 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429\\\\0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858\\\\0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858\\\\0.0857142857142857 & 0.0857142857142858 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142858 & 0.0857142857142858\\\\0.0857142857142857 & 0.0857142857142858 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142858 & 0.0857142857142858\\\\0.228571428571429 & 0.228571428571429 & 0.228571428571429 & 0.228571428571429 & 0.228571428571429 & 0.228571428571428 & 0.228571428571428 & 0.228571428571429 & 0.228571428571429 & 0.228571428571429 & 0.228571428571429\\\\0.0857142857142857 & 0.0857142857142858 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142858 & 0.0857142857142858\\\\0.0857142857142857 & 0.0857142857142858 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142858 & 0.0857142857142858\\\\0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858\\\\0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142857 & 0.0857142857142858 & 0.0857142857142858 & 0.0857142857142858\\\\0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571428 & 0.0428571428571428 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429 & 0.0428571428571429\\end{array}\\right]$"
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 2: each column converges to:\n",
        "        [0.0428\n",
        "          0.0857\n",
        "          ...\n",
        "          0.228\n",
        "          ...\n",
        "          0.0857\n",
        "          0.0428]"
      ],
      "metadata": {
        "id": "annrAj8Dba2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(d) Interpret limits**\n",
        "\n",
        "Explain your findings in part (c) in terms of our play."
      ],
      "metadata": {
        "id": "tohAcKbFbcFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: after a long time this is where the attention will be split"
      ],
      "metadata": {
        "id": "3nIC-olRb0Il"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(e) Interpret eigenvectors**\n",
        "What do eigenvectors represent in our scenario?"
      ],
      "metadata": {
        "id": "iM8dDpB-cewR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: they represnt where the attention will go after a long time has passed"
      ],
      "metadata": {
        "id": "CcUUux0tcoKb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SLD4HTzRd6-G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}